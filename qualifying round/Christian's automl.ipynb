{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y5q5nRyZUN2i"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "GPK0sjaAWJox",
    "outputId": "94737fbe-708a-47be-ffd2-31df3d81f4e6"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            ID                                               text  sentiment\n",
       "0        21098  .с.,и спросил его:  о Посланник Аллаха!Ты пори...          1\n",
       "1        21099  Роднее всех родных Попала я в ГКБ №8 еще в дек...          1\n",
       "2        21100  Непорядочное отношение к своим работникам Рабо...          2\n",
       "3        21101  ). Отсутствуют нормативы, Госты и прочее, что ...          1\n",
       "4        21102             У меня машина в руках 5 лет и это п...          1\n",
       "...        ...                                                ...        ...\n",
       "189886  210984  Мой юбилей я отмечал в ресторане \" Астория \" ....          2\n",
       "189887  210985  Отлично встретили, разместили в роскошном номе...          1\n",
       "189888  210986  Была в Васаби на ст. метро Сенная .  Во первых...          0\n",
       "189889  210987  Ребята не стоит смотреть этот фильм. Вы молоды...          0\n",
       "189890  210988  Про махание руками нигде  не нашел.  Почему се...          1\n",
       "\n",
       "[189891 rows x 3 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-de04a2c5-c4d0-4ce7-b870-2fbb97240f97\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21098</td>\n",
       "      <td>.с.,и спросил его:  о Посланник Аллаха!Ты пори...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21099</td>\n",
       "      <td>Роднее всех родных Попала я в ГКБ №8 еще в дек...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21100</td>\n",
       "      <td>Непорядочное отношение к своим работникам Рабо...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21101</td>\n",
       "      <td>). Отсутствуют нормативы, Госты и прочее, что ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21102</td>\n",
       "      <td>У меня машина в руках 5 лет и это п...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189886</th>\n",
       "      <td>210984</td>\n",
       "      <td>Мой юбилей я отмечал в ресторане \" Астория \" ....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189887</th>\n",
       "      <td>210985</td>\n",
       "      <td>Отлично встретили, разместили в роскошном номе...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189888</th>\n",
       "      <td>210986</td>\n",
       "      <td>Была в Васаби на ст. метро Сенная .  Во первых...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189889</th>\n",
       "      <td>210987</td>\n",
       "      <td>Ребята не стоит смотреть этот фильм. Вы молоды...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189890</th>\n",
       "      <td>210988</td>\n",
       "      <td>Про махание руками нигде  не нашел.  Почему се...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189891 rows × 3 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de04a2c5-c4d0-4ce7-b870-2fbb97240f97')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-de04a2c5-c4d0-4ce7-b870-2fbb97240f97 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-de04a2c5-c4d0-4ce7-b870-2fbb97240f97');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-fe54c87f-34c5-4b31-891a-9d41ff9faa69\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe54c87f-34c5-4b31-891a-9d41ff9faa69')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-fe54c87f-34c5-4b31-891a-9d41ff9faa69 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      }
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightautoml\r\n",
      "  Using cached lightautoml-0.3.8.1-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting autowoe>=1.2 (from lightautoml)\r\n",
      "  Using cached AutoWoE-1.3.2-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting catboost>=0.26.1 (from lightautoml)\r\n",
      "  Using cached catboost-1.2.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (1.2 kB)\r\n",
      "Collecting cmaes (from lightautoml)\r\n",
      "  Using cached cmaes-0.10.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting holidays (from lightautoml)\r\n",
      "  Using cached holidays-0.45-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: jinja2 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (3.1.3)\r\n",
      "Collecting joblib<1.3.0 (from lightautoml)\r\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting json2html (from lightautoml)\r\n",
      "  Using cached json2html-1.3.0-py3-none-any.whl\r\n",
      "Collecting lightgbm<=3.2.1,>=2.3 (from lightautoml)\r\n",
      "  Using cached lightgbm-3.2.1.tar.gz (1.5 MB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: networkx in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (3.2.1)\r\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (1.23.5)\r\n",
      "Collecting optuna (from lightautoml)\r\n",
      "  Using cached optuna-3.6.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: pandas<2.0.0 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (1.5.3)\r\n",
      "Collecting poetry-core<2.0.0,>=1.0.0 (from lightautoml)\r\n",
      "  Using cached poetry_core-1.9.0-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: pyyaml in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (6.0.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (1.4.0)\r\n",
      "Requirement already satisfied: seaborn in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (0.13.2)\r\n",
      "Collecting statsmodels<=0.14.0 (from lightautoml)\r\n",
      "  Using cached statsmodels-0.14.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\r\n",
      "Collecting torch<=2.0.0,>=1.9.0 (from lightautoml)\r\n",
      "  Using cached torch-2.0.0-cp311-none-macosx_11_0_arm64.whl.metadata (23 kB)\r\n",
      "Requirement already satisfied: tqdm in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightautoml) (4.64.1)\r\n",
      "Collecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.2->lightautoml)\r\n",
      "  Using cached StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: matplotlib in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from autowoe>=1.2->lightautoml) (3.8.3)\r\n",
      "Collecting pytest (from autowoe>=1.2->lightautoml)\r\n",
      "  Using cached pytest-8.1.1-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Requirement already satisfied: pytz in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from autowoe>=1.2->lightautoml) (2024.1)\r\n",
      "Requirement already satisfied: scipy in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from autowoe>=1.2->lightautoml) (1.10.0)\r\n",
      "Collecting sphinx (from autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinx-7.2.6-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting sphinx-rtd-theme (from autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Collecting graphviz (from catboost>=0.26.1->lightautoml)\r\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting plotly (from catboost>=0.26.1->lightautoml)\r\n",
      "  Using cached plotly-5.20.0-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: six in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from catboost>=0.26.1->lightautoml) (1.16.0)\r\n",
      "Requirement already satisfied: wheel in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.43.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from pandas<2.0.0->lightautoml) (2.8.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from scikit-learn>=0.22->lightautoml) (3.4.0)\r\n",
      "Collecting patsy>=0.5.2 (from statsmodels<=0.14.0->lightautoml)\r\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from statsmodels<=0.14.0->lightautoml) (23.2)\r\n",
      "Requirement already satisfied: filelock in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (3.9.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (1.12)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from jinja2->lightautoml) (2.1.5)\r\n",
      "Collecting alembic>=1.5.0 (from optuna->lightautoml)\r\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Collecting colorlog (from optuna->lightautoml)\r\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna->lightautoml)\r\n",
      "  Using cached SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\r\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->lightautoml)\r\n",
      "  Using cached Mako-1.3.2-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.50.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=8 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.1.2)\r\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost>=0.26.1->lightautoml)\r\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Collecting iniconfig (from pytest->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting pluggy<2.0,>=1.4 (from pytest->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached pluggy-1.4.0-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting sphinxcontrib-applehelp (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-devhelp (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-jsmath (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting sphinxcontrib-qthelp (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: Pygments>=2.14 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.17.2)\r\n",
      "Collecting docutils<0.21,>=0.18.1 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting snowballstemmer>=2.0 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: babel>=2.9 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.14.0)\r\n",
      "Collecting alabaster<0.8,>=0.7 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting imagesize>=1.3 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: requests>=2.25.0 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.31.0)\r\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->autowoe>=1.2->lightautoml)\r\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml) (1.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml) (2024.2.2)\r\n",
      "Using cached lightautoml-0.3.8.1-py3-none-any.whl (416 kB)\r\n",
      "Using cached AutoWoE-1.3.2-py3-none-any.whl (215 kB)\r\n",
      "Using cached catboost-1.2.3-cp311-cp311-macosx_11_0_universal2.whl (26.2 MB)\r\n",
      "Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "Using cached poetry_core-1.9.0-py3-none-any.whl (309 kB)\r\n",
      "Using cached statsmodels-0.14.0-cp311-cp311-macosx_11_0_arm64.whl (9.4 MB)\r\n",
      "Using cached torch-2.0.0-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\r\n",
      "Using cached cmaes-0.10.0-py3-none-any.whl (29 kB)\r\n",
      "Using cached holidays-0.45-py3-none-any.whl (932 kB)\r\n",
      "Using cached optuna-3.6.0-py3-none-any.whl (379 kB)\r\n",
      "Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\r\n",
      "Using cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\r\n",
      "Using cached SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\r\n",
      "Using cached StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\r\n",
      "Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)\r\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\r\n",
      "Using cached plotly-5.20.0-py3-none-any.whl (15.7 MB)\r\n",
      "Using cached pytest-8.1.1-py3-none-any.whl (337 kB)\r\n",
      "Using cached sphinx-7.2.6-py3-none-any.whl (3.2 MB)\r\n",
      "Using cached sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\r\n",
      "Using cached alabaster-0.7.16-py3-none-any.whl (13 kB)\r\n",
      "Using cached docutils-0.20.1-py3-none-any.whl (572 kB)\r\n",
      "Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\r\n",
      "Using cached pluggy-1.4.0-py3-none-any.whl (20 kB)\r\n",
      "Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\r\n",
      "Using cached sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\r\n",
      "Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\r\n",
      "Using cached sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\r\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\r\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\r\n",
      "Using cached Mako-1.3.2-py3-none-any.whl (78 kB)\r\n",
      "Using cached sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\r\n",
      "Using cached sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\r\n",
      "Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\r\n",
      "Using cached sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\r\n",
      "Building wheels for collected packages: lightgbm\r\n",
      "  Building wheel for lightgbm (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py bdist_wheel\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[101 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:running bdist_wheel\r\n",
      "  \u001B[31m   \u001B[0m /private/var/folders/q4/rd43y_g54plgx59m_wvf7lzr0000gn/T/pip-install-i8td4yg8/lightgbm_6ba90c4043b84f7baae3167c0da3b22f/setup.py:221: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n",
      "  \u001B[31m   \u001B[0m !!\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m         ********************************************************************************\r\n",
      "  \u001B[31m   \u001B[0m         Please avoid running ``setup.py`` directly.\r\n",
      "  \u001B[31m   \u001B[0m         Instead, use pypa/build, pypa/installer or other\r\n",
      "  \u001B[31m   \u001B[0m         standards-based tools.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m         See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n",
      "  \u001B[31m   \u001B[0m         ********************************************************************************\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m !!\r\n",
      "  \u001B[31m   \u001B[0m   install.initialize_options(self)\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:running build\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:running build_py\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:creating build\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:creating build/lib\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:creating build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/callback.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/compat.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/plotting.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/__init__.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/engine.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/dask.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/basic.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/libpath.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/sklearn.py -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:running egg_info\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:writing lightgbm.egg-info/PKG-INFO\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:writing dependency_links to lightgbm.egg-info/dependency_links.txt\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:writing requirements to lightgbm.egg-info/requires.txt\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:writing top-level names to lightgbm.egg-info/top_level.txt\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:reading manifest file 'lightgbm.egg-info/SOURCES.txt'\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:reading manifest template 'MANIFEST.in'\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:no previously-included directories found matching 'build'\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:warning: no files found matching '*.so' under directory 'lightgbm'\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:warning: no files found matching '*.so' under directory 'compile'\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:warning: no files found matching '*.dll' under directory 'compile/Release'\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:warning: no previously-included files matching '*.py[co]' found anywhere in distribution\r\n",
      "  \u001B[31m   \u001B[0m WARNING:root:warning: no previously-included files found matching 'compile/external_libs/compute/.git'\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:adding license file 'LICENSE'\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:writing manifest file 'lightgbm.egg-info/SOURCES.txt'\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:copying lightgbm/VERSION.txt -> build/lib/lightgbm\r\n",
      "  \u001B[31m   \u001B[0m INFO:wheel:installing to build/bdist.macosx-10.9-universal2/wheel\r\n",
      "  \u001B[31m   \u001B[0m INFO:root:running install\r\n",
      "  \u001B[31m   \u001B[0m INFO:LightGBM:Starting to compile the library.\r\n",
      "  \u001B[31m   \u001B[0m INFO:LightGBM:Starting to compile with CMake.\r\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/q4/rd43y_g54plgx59m_wvf7lzr0000gn/T/pip-install-i8td4yg8/lightgbm_6ba90c4043b84f7baae3167c0da3b22f/setup.py\", line 107, in silent_call\r\n",
      "  \u001B[31m   \u001B[0m     subprocess.check_call(cmd, stderr=log, stdout=log)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 408, in check_call\r\n",
      "  \u001B[31m   \u001B[0m     retcode = call(*popenargs, **kwargs)\r\n",
      "  \u001B[31m   \u001B[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 389, in call\r\n",
      "  \u001B[31m   \u001B[0m     with Popen(*popenargs, **kwargs) as p:\r\n",
      "  \u001B[31m   \u001B[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1022, in __init__\r\n",
      "  \u001B[31m   \u001B[0m     self._execute_child(args, executable, preexec_fn, close_fds,\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1899, in _execute_child\r\n",
      "  \u001B[31m   \u001B[0m     raise child_exception_type(errno_num, err_msg, err_filename)\r\n",
      "  \u001B[31m   \u001B[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m During handling of the above exception, another exception occurred:\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\r\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 2, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/q4/rd43y_g54plgx59m_wvf7lzr0000gn/T/pip-install-i8td4yg8/lightgbm_6ba90c4043b84f7baae3167c0da3b22f/setup.py\", line 335, in <module>\r\n",
      "  \u001B[31m   \u001B[0m     setup(name='lightgbm',\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/__init__.py\", line 104, in setup\r\n",
      "  \u001B[31m   \u001B[0m     return distutils.core.setup(**attrs)\r\n",
      "  \u001B[31m   \u001B[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n",
      "  \u001B[31m   \u001B[0m     return run_commands(dist)\r\n",
      "  \u001B[31m   \u001B[0m            ^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n",
      "  \u001B[31m   \u001B[0m     dist.run_commands()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n",
      "  \u001B[31m   \u001B[0m     self.run_command(cmd)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/dist.py\", line 967, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     super().run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     cmd_obj.run()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/wheel/bdist_wheel.py\", line 403, in run\r\n",
      "  \u001B[31m   \u001B[0m     self.run_command(\"install\")\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     self.distribution.run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/dist.py\", line 967, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     super().run_command(command)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n",
      "  \u001B[31m   \u001B[0m     cmd_obj.run()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/q4/rd43y_g54plgx59m_wvf7lzr0000gn/T/pip-install-i8td4yg8/lightgbm_6ba90c4043b84f7baae3167c0da3b22f/setup.py\", line 249, in run\r\n",
      "  \u001B[31m   \u001B[0m     compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu, use_cuda=self.cuda, use_mpi=self.mpi,\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/q4/rd43y_g54plgx59m_wvf7lzr0000gn/T/pip-install-i8td4yg8/lightgbm_6ba90c4043b84f7baae3167c0da3b22f/setup.py\", line 199, in compile_cpp\r\n",
      "  \u001B[31m   \u001B[0m     silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake and all required dependencies first')\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/q4/rd43y_g54plgx59m_wvf7lzr0000gn/T/pip-install-i8td4yg8/lightgbm_6ba90c4043b84f7baae3167c0da3b22f/setup.py\", line 111, in silent_call\r\n",
      "  \u001B[31m   \u001B[0m     raise Exception(\"\\n\".join((error_msg, LOG_NOTICE)))\r\n",
      "  \u001B[31m   \u001B[0m Exception: Please install CMake and all required dependencies first\r\n",
      "  \u001B[31m   \u001B[0m The full version of error log was saved into /Users/antontagiev/LightGBM_compilation.log\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[31m  ERROR: Failed building wheel for lightgbm\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25h  Running setup.py clean for lightgbm\r\n",
      "Failed to build lightgbm\r\n",
      "\u001B[31mERROR: Could not build wheels for lightgbm, which is required to install pyproject.toml-based projects\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U lightautoml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:24:32.264108Z",
     "start_time": "2024-03-25T15:24:27.892026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "train, test = train_test_split(data.iloc[:100000], test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "id": "ShsvrC4GVO8-"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\r\n",
      "  Using cached lightgbm-4.3.0.tar.gz (1.7 MB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Installing backend dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightgbm) (1.23.5)\r\n",
      "Requirement already satisfied: scipy in /Users/antontagiev/PycharmProjects/text_summarization_sirius/venv/lib/python3.11/site-packages (from lightgbm) (1.10.0)\r\n",
      "Building wheels for collected packages: lightgbm\r\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001B[?25l/"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-25T16:34:31.634470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from lightautoml.automl.presets.text_presets import TabularNLPAutoML\n",
    "from lightautoml.tasks import Task"
   ],
   "metadata": {
    "id": "KbR0Yk2kYOtk"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "roles = {\n",
    "    'text': ['text'],\n",
    "    'drop': ['ID'],\n",
    "    'target': 'sentiment',\n",
    "}\n",
    "\n",
    "task = Task('multiclass')"
   ],
   "metadata": {
    "id": "HSGlOnUUV75L"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "automl = TabularNLPAutoML(\n",
    "    task=task,\n",
    "    cpu_limit=1, gpu_ids='0',\n",
    "    text_params = {'lang': 'ru', 'bert_model': 'DeepPavlov/rubert-base-cased-conversational'},\n",
    "    autonlp_params={\n",
    "        'model_name': 'random_lstm',\n",
    "        'transformer_params': {\n",
    "            'model_params': {\n",
    "                'embed_size': 300,\n",
    "                'hidden_size': 256,\n",
    "                'pooling': 'mean',\n",
    "                'num_layers': 2,\n",
    "            },\n",
    "            'dataset_params': {'embed_size': 300},\n",
    "        },\n",
    "    },\n",
    "    nn_params={\n",
    "        'max_length': 256,\n",
    "        'bs': 1,\n",
    "        'n_epochs': 10,\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "id": "Vay_hA_XWr1W"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "oof_pred = automl.fit_predict(train, roles=roles, verbose=10)\n",
    "test_pred = automl.predict(test)\n",
    "not_nan = np.any(~np.isnan(oof_pred.data), axis=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckaqcaAVl3iR",
    "outputId": "1ec95b2e-49d1-40f0-b340-7334ad48cd8e"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] Stdout logging level is DEBUG.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] Model language mode: ru\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.automl.presets.text_presets:Model language mode: ru\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] Task: multiclass\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: multiclass\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] - time: 3600.00 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] - CPU: 4 cores\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] \u001B[1mTrain data shape: (3500, 3)\u001B[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.reader.base:\u001B[1mTrain data shape: (3500, 3)\u001B[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:15] Layer \u001B[1m1\u001B[0m train process start. Time left 3599.90 secs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001B[1m1\u001B[0m train process start. Time left 3599.90 secs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:21] Start fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:21] Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:21] ===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 1e-05 score = -1.0456832925911124\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -1.0456832925911124\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 5e-05 score = -1.0455406004286631\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -1.0455406004286631\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.0001 score = -1.0453509466560573\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -1.0453509466560573\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.0005 score = -1.0438798456182168\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -1.0438798456182168\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.001 score = -1.0421007291619395\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -1.0421007291619395\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.005 score = -1.0284163985309178\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -1.0284163985309178\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.01 score = -1.013100657813463\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -1.013100657813463\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.05 score = -0.9327489420820732\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.9327489420820732\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.1 score = -0.8809825812602404\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.8809825812602404\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 0.5 score = -0.7713874752294841\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.7713874752294841\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:22] Linear model: C = 1 score = -0.7447252061092797\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.7447252061092797\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 5 score = -0.7281167759413245\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.7281167759413245\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 10 score = -0.7281167759413245\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = -0.7281167759413245\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 50 score = -0.7374069613898723\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 50 score = -0.7374069613898723\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] ===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 1e-05 score = -1.046240342283401\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -1.046240342283401\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 5e-05 score = -1.046088809445289\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -1.046088809445289\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 0.0001 score = -1.0459194277786843\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -1.0459194277786843\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 0.0005 score = -1.0444641890064907\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -1.0444641890064907\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 0.001 score = -1.0426470325515582\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -1.0426470325515582\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 0.005 score = -1.028858735755662\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -1.028858735755662\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 0.01 score = -1.0137844294166967\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -1.0137844294166967\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:23] Linear model: C = 0.05 score = -0.9337505836805249\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.9337505836805249\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 0.1 score = -0.8824497392270862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.8824497392270862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 0.5 score = -0.7721112113680002\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.7721112113680002\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 1 score = -0.7454086668836357\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.7454086668836357\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 5 score = -0.7289145921085077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.7289145921085077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 10 score = -0.7289145921085077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = -0.7289145921085077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 50 score = -0.7394469951644926\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 50 score = -0.7394469951644926\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] ===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 1e-05 score = -1.0459682421757432\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -1.0459682421757432\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 5e-05 score = -1.045810619853982\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -1.045810619853982\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 0.0001 score = -1.045624367790807\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -1.045624367790807\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:24] Linear model: C = 0.0005 score = -1.044091906479766\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -1.044091906479766\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 0.001 score = -1.0422484025140706\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -1.0422484025140706\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 0.005 score = -1.0278114509174918\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -1.0278114509174918\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 0.01 score = -1.0118640012817302\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -1.0118640012817302\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 0.05 score = -0.9277044564259078\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.9277044564259078\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 0.1 score = -0.8716835697344822\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.8716835697344822\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 0.5 score = -0.7530781597895954\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.7530781597895954\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 1 score = -0.7244078354944594\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.7244078354944594\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 5 score = -0.70984653081622\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.70984653081622\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 10 score = -0.70984653081622\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = -0.70984653081622\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Linear model: C = 50 score = -0.709846653578441\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 50 score = -0.709846653578441\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m finished. score = \u001B[1m-0.7222961889845335\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m finished. score = \u001B[1m-0.7222961889845335\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m fitting and predicting completed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m fitting and predicting completed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:25:25] Time left 3589.86 secs\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.base:Time left 3589.86 secs\n",
      "\n",
      "100%|██████████| 3500/3500 [00:35<00:00, 99.53it/s] \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:24] Feature concated__text fitted\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text fitted\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:47] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:47] Start fitting \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:47] Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:47] ===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:48] Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:49] [100]\tvalid's multi_logloss: 0.987941\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.987941\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:50] [200]\tvalid's multi_logloss: 0.968788\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.968788\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:51] [300]\tvalid's multi_logloss: 0.960661\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.960661\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:54] [400]\tvalid's multi_logloss: 0.957363\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.957363\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:56] [500]\tvalid's multi_logloss: 0.956203\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.956203\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:57] [600]\tvalid's multi_logloss: 0.95666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.95666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:58] Early stopping, best iteration is:\n",
      "[490]\tvalid's multi_logloss: 0.955917\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[490]\tvalid's multi_logloss: 0.955917\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:59] ===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:26:59] Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:00] [100]\tvalid's multi_logloss: 0.987352\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.987352\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:01] [200]\tvalid's multi_logloss: 0.967234\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.967234\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:02] [300]\tvalid's multi_logloss: 0.959826\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.959826\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:03] [400]\tvalid's multi_logloss: 0.957463\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.957463\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:04] [500]\tvalid's multi_logloss: 0.954894\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.954894\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:11] [600]\tvalid's multi_logloss: 0.955684\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.955684\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:15] [700]\tvalid's multi_logloss: 0.957144\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.957144\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:17] Early stopping, best iteration is:\n",
      "[547]\tvalid's multi_logloss: 0.954505\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[547]\tvalid's multi_logloss: 0.954505\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:18] ===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:18] Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:31] [100]\tvalid's multi_logloss: 0.989389\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.989389\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:41] [200]\tvalid's multi_logloss: 0.969594\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.969594\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:44] [300]\tvalid's multi_logloss: 0.959625\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.959625\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:47] [400]\tvalid's multi_logloss: 0.955646\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.955646\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:50] [500]\tvalid's multi_logloss: 0.954524\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.954524\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:27:57] [600]\tvalid's multi_logloss: 0.953855\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.953855\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:00] [700]\tvalid's multi_logloss: 0.955025\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.955025\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:03] Early stopping, best iteration is:\n",
      "[573]\tvalid's multi_logloss: 0.953679\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[573]\tvalid's multi_logloss: 0.953679\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Fitting \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m finished. score = \u001B[1m-0.9547007402117782\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m finished. score = \u001B[1m-0.9547007402117782\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m fitting and predicting completed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m fitting and predicting completed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Time left 3431.71 secs\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.base:Time left 3431.71 secs\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] \u001B[1mLayer 1 training completed.\u001B[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.base:\u001B[1mLayer 1 training completed.\u001B[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Blending: optimization starts with equal weights and score \u001B[1m-0.7763245206059187\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001B[1m-0.7763245206059187\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Blending: iteration \u001B[1m0\u001B[0m: score = \u001B[1m-0.7206274184704453\u001B[0m, weights = \u001B[1m[0.9249973  0.07500266]\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001B[1m0\u001B[0m: score = \u001B[1m-0.7206274184704453\u001B[0m, weights = \u001B[1m[0.9249973  0.07500266]\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Blending: iteration \u001B[1m1\u001B[0m: score = \u001B[1m-0.7206274184704453\u001B[0m, weights = \u001B[1m[0.9249973  0.07500266]\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001B[1m1\u001B[0m: score = \u001B[1m-0.7206274184704453\u001B[0m, weights = \u001B[1m[0.9249973  0.07500266]\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] \u001B[1mAutoml preset training completed in 168.85 seconds\u001B[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001B[1mAutoml preset training completed in 168.85 seconds\u001B[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:04] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.92500 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.07500 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.92500 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.07500 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:28:26] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred1 = []\n",
    "for i in oof_pred:\n",
    "    pred1.append(np.argmax(i.data))\n",
    "\n",
    "pred2 = []\n",
    "for i in test_pred:\n",
    "    pred2.append(np.argmax(i.data))"
   ],
   "metadata": {
    "id": "7dl6mdgvdxZB"
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "oof_pred = np.array"
   ],
   "metadata": {
    "id": "4yIHg1RRhpVE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "id": "Rb3fNumRdm7i"
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('Check scores:')\n",
    "print('OOF score: {}'.format(f1_score(train[roles['target']].values[not_nan], np.array(pred1), average=None)))\n",
    "print('TEST score: {}'.format(f1_score(test[roles['target']].values, np.array(pred2), average=None)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IH5mUQamY-C4",
    "outputId": "6bd3bc3e-9559-4299-88f4-9c376bf57f31"
   },
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Check scores:\n",
      "OOF score: [0.52470588 0.7332959  0.65822785]\n",
      "TEST score: [0.57978723 0.75128205 0.63662791]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train[roles['target']].values[not_nan]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qhh6reQiCkS",
    "outputId": "67f9ae15-5aa5-4cb5-eda1-e7ef271adb0c"
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 0, 1, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "z77bUvudjNZ5",
    "outputId": "2cbd51cf-f261-4516-d377-67e9e8ba30fa"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          ID                                               text\n",
       "0          0  Развода на деньги нет Наблюдаюсь в Лайфклиник ...\n",
       "1          1  Отель выбрали потому что рядом со стадионом. О...\n",
       "2          2  Вылечили Гноился с рождения глазик, в поликлин...\n",
       "3          3  Хорошее расположение.С вокзала дошли пешком.Но...\n",
       "4          4  Отличное месторасположение,прекрасный вид,особ...\n",
       "...      ...                                                ...\n",
       "21093  21093  Несколько лет назад муж останавливался в этом ...\n",
       "21094  21094  Спасли от боли После родов у меня появились бо...\n",
       "21095  21095  з ролика понятно одно - девушка- наблюдатель  ...\n",
       "21096  21096  Остались всем довольны, дружелюбный персонал, ...\n",
       "21097  21097  Спасибо огромное за сыночка Хочу выразить огро...\n",
       "\n",
       "[21098 rows x 2 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-3177f677-3b11-493a-ab8e-6d8cf012706c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Развода на деньги нет Наблюдаюсь в Лайфклиник ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Отель выбрали потому что рядом со стадионом. О...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Вылечили Гноился с рождения глазик, в поликлин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Хорошее расположение.С вокзала дошли пешком.Но...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Отличное месторасположение,прекрасный вид,особ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21093</th>\n",
       "      <td>21093</td>\n",
       "      <td>Несколько лет назад муж останавливался в этом ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21094</th>\n",
       "      <td>21094</td>\n",
       "      <td>Спасли от боли После родов у меня появились бо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21095</th>\n",
       "      <td>21095</td>\n",
       "      <td>з ролика понятно одно - девушка- наблюдатель  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21096</th>\n",
       "      <td>21096</td>\n",
       "      <td>Остались всем довольны, дружелюбный персонал, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21097</th>\n",
       "      <td>21097</td>\n",
       "      <td>Спасибо огромное за сыночка Хочу выразить огро...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21098 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3177f677-3b11-493a-ab8e-6d8cf012706c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3177f677-3b11-493a-ab8e-6d8cf012706c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3177f677-3b11-493a-ab8e-6d8cf012706c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-40cef527-f8af-42ec-a5b5-2f123b39f481\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40cef527-f8af-42ec-a5b5-2f123b39f481')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-40cef527-f8af-42ec-a5b5-2f123b39f481 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "test",
       "summary": "{\n  \"name\": \"test\",\n  \"rows\": 21098,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6090,\n        \"min\": 0,\n        \"max\": 21097,\n        \"num_unique_values\": 21098,\n        \"samples\": [\n          17342,\n          1805,\n          4230\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20961,\n        \"samples\": [\n          \"\\u0430 \\u043f\\u0440\\u043e\\u0442\\u044f\\u0436\\u0435\\u043d\\u0438\\u0438 \\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u0438\\u0445 \\u0447\\u0430\\u0441\\u043e\\u0432 \\u043f\\u043e\\u0441\\u043b\\u0435 \\u0435\\u0434\\u044b \\u0443\\u0440\\u043e\\u0432\\u0435\\u043d\\u044c \\u0441\\u0430\\u0445\\u0430\\u0440\\u0430 \\u0432 \\u043a\\u0440\\u043e\\u0432\\u0438 \\u0432\\u0441\\u0435\\u0433\\u0434\\u0430 \\u043f\\u043e\\u0432\\u044b\\u0448\\u0435\\u043d. \\u0422\\u0430\\u043a\\u043e\\u0435 \\u044f\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435 \\u0441\\u0432\\u044f\\u0437\\u0430\\u043d\\u043e \\u0441 \\u043e\\u0441\\u043e\\u0431\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u044f\\u043c\\u0438 \\u0443\\u0441\\u0432\\u043e\\u0435\\u043d\\u0438\\u044f \\u043f\\u0438\\u0449\\u0438     \\u0444\\u0438\\u0437\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u043d\\u0430\\u0433\\u0440\\u0443\\u0437\\u043a\\u0430 \\u043c\\u0435\\u043d\\u044c\\u0448\\u0435 \\u043f\\u0440\\u0438\\u0432\\u044b\\u0447\\u043d\\u043e\\u0439     \\u0441\\u0442\\u0440\\u0435\\u0441\\u0441\\u044b, \\u0432\\u043e\\u043b\\u043d\\u0435\\u043d\\u0438\\u044f, \\u0433\\u043b\\u0443\\u0431\\u043e\\u043a\\u0438\\u0435 \\u044d\\u043c\\u043e\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u044b\\u0435 \\u043f\\u0435\\u0440\\u0435\\u0436\\u0438\\u0432\\u0430\\u043d\\u0438\\u044f     \\u043a\\u0443\\u0440\\u0435\\u043d\\u0438\\u0435 \\u0438 \\u0434\\u0440\\u0443\\u0433\\u0438\\u0435 \\u0432\\u0440\\u0435\\u0434\\u043d\\u044b\\u0435 \\u043f\\u0440\\u0438\\u0432\\u044b\\u0447\\u043a\\u0438     \\u043f\\u0440\\u0435\\u0434\\u043c\\u0435\\u043d\\u0441\\u0442\\u0440\\u0443\\u0430\\u043b\\u044c\\u043d\\u044b\\u0439 \\u0441\\u0438\\u043d\\u0434\\u0440\\u043e\\u043c \\u0443 \\u0436\\u0435\\u043d\\u0449\\u0438\\u043d.\\u0418\\u043c\\u0435\\u044e\\u0442\\u0441\\u044f \\u0442\\u0430\\u043a\\u0436\\u0435 \\u043f\\u0440\\u0438\\u0447\\u0438\\u043d\\u044b \\u043f\\u043e\\u0432\\u044b\\u0448\\u0435\\u043d\\u0438\\u044f \\u0441\\u0430\\u0445\\u0430\\u0440\\u0430, \\u0441\\u0432\\u044f\\u0437\\u0430\\u043d\\u043d\\u044b\\u0435 \\u0441 \\u0440\\u0430\\u0437\\u043b\\u0438\\u0447\\u043d\\u044b\\u043c\\u0438 \\u043d\\u0430\\u0440\\u0443\\u0448\\u0435\\u043d\\u0438\\u044f\\u043c\\u0438 \\u0437\\u0434\\u043e\\u0440\\u043e\\u0432\\u044c\\u044f. \\u0418\\u0445 \\u0434\\u0435\\u043b\\u044f\\u0442 \\u043d\\u0430 \\u0432\\u0438\\u0434\\u044b \\u0432 \\u0437\\u0430\\u0432\\u0438\\u0441\\u0438\\u043c\\u043e\\u0441\\u0442\\u0438 \\u043e\\u0442 \\u0442\\u043e\\u0433\\u043e, \\u0431\\u043e\\u043b\\u0435\\u0437\\u043d\\u044c \\u043a\\u0430\\u043a\\u043e\\u0433\\u043e \\u043e\\u0440\\u0433\\u0430\\u043d\\u0430 \\u0438\\u043b\\u0438 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u044b \\u0434\\u0438\\u0430\\u0433\\u043d\\u043e\\u0441\\u0442\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f. \\u0412 \\u0441\\u043e\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0438\\u0438 \\u0441 \\u044d\\u0442\\u0438\\u043c \\u0432\\u044b\\u0434\\u0435\\u043b\\u044f\\u044e\\u0442 \\u0442\\u0430\\u043a\\u0438\\u0435 \\u0433\\u0440\\u0443\\u043f\\u043f\\u044b \\u0444\\u0430\\u043a\\u0442\\u043e\\u0440\\u043e\\u0432, \\u0441\\u043f\\u043e\\u0441\\u043e\\u0431\\u0441\\u0442\\u0432\\u0443\\u044e\\u0449\\u0438\\u0445 \\u0433\\u0438\\u043f\\u0435\\u0440\\u0433\\u043b\\u0438\\u043a\\u0435\\u043c\\u0438\\u0438, \\u043a\\u0430\\u043a:    \\u044d\\u043d\\u0434\\u043e\\u043a\\u0440\\u0438\\u043d\\u043d\\u044b\\u0435. \\u041d\\u0430\\u0440\\u0443\\u0448\\u0435\\u043d\\u0438\\u0435 \\u0432\\u044b\\u0440\\u0430\\u0431\\u043e\\u0442\\u043a\\u0438 \\u0433\\u043e\\u0440\\u043c\\u043e\\u043d\\u043e\\u0432 \\u043c\\u043e\\u0436\\u0435\\u0442 \\u043d\\u0430\\u0431\\u043b\\u044e\\u0434\\u0430\\u0442\\u044c\\u0441\\u044f \\u043f\\u0440\\u0438 \\u0440\\u0430\\u0437\\u043b\\u0438\\u0447\\u043d\\u044b\\u0445 \\u0437\\u0430\\u0431\\u043e\\u043b\\u0435\\u0432\\u0430\\u043d\\u0438\\u044f\\u0445 \\u044d\\u0442\\u043e\\u0439 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u044b \\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u043c\\u0430. \\u0421\\u0440\\u0435\\u0434\\u0438 \\u043d\\u0438\\u0445: \\u0441\\u0430\\u0445\\u0430\\u0440\\u043d\\u044b\\u0439 \\u0434\\u0438\\u0430\\u0431\\u0435\\u0442 (\\u043d\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0442\\u043e\\u0447\\u043d\\u043e\\u0441\\u0442\\u044c \\u0438\\u043d\\u0441\\u0443\\u043b\\u0438\\u043d\\u0430), \\u0444\\u0435\\u043e\\u0445\\u0440\\u043e\\u043c\\u043e\\u0446\\u0438\\u0442\\u043e\\u043c\\u0430, \\u0442\\u0438\\u0440\\u0435\\u043e\\u0442\\u043e\\u043a\\u0441\\u0438\\u043a\\u043e\\u0437, \\u0431\\u043e\\u043b\\u0435\\u0437\\u043d\\u044c \\u041a\\u0443\\u0448\\u0438\\u043d\\u0433\\u0430. \\u041f\\u0440\\u0438 \\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0445 \\u0442\\u0440\\u0435\\u0445 \\u0437\\u0430\\u0431\\u043e\\u043b\\u0435\\u0432\\u0430\\u043d\\u0438\\u044f\\u0445 \\u0432 \\u043a\\u0440\\u043e\\u0432\\u0438 \\u0440\\u0430\\u0441\\u0442\\u0435\\u0442 \\u0443\\u0440\\u043e\\u0432\\u0435\\u043d\\u044c \\u0433\\u043e\\u0440\\u043c\\u043e\\u043d\\u043e\\u0432, \\u0441\\u043f\\u043e\\u0441\\u043e\\u0431\\u0441\\u0442\\u0432\\u0443\\u044e\\u0449\\u0438\\u0445 \\u0443\\u0432\\u0435\\u043b\\u0438\\u0447\\u0435\\u043d\\u0438\\u044e \\u043a\\u043e\\u043b\\u0438\\u0447\\u0435\\u0441\\u0442\\u0432\\u0430 \\u0433\\u043b\\u044e\\u043a\\u043e\\u0437\\u044b, \\u043d\\u0430\\u043f\\u0440\\u0438\\u043c\\u0435\\u0440, \\u0430\\u0434\\u0440\\u0435\\u043d\\u0430\\u043b\\u0438\\u043d\\u0430     \\u0431\\u043e\\u043b\\u0435\\u0437\\u043d\\u0438 \\u043f\\u043e\\u0434\\u0436\\u0435\\u043b\\u0443\\u0434\\u043e\\u0447\\u043d\\u043e\\u0439 \\u0436\\u0435\\u043b\\u0435\\u0437\\u044b. \\u041f\\u0440\\u0438 \\u043f\\u0430\\u043d\\u043a\\u0440\\u0438\\u0430\\u0442\\u0438\\u0442\\u0435, \\u043e\\u043f\\u0443\\u0445\\u043e\\u043b\\u044f\\u0445 \\u0438 \\u0434\\u0440\\u0443\\u0433\\u0438\\u0445 \\u043d\\u0430\\u0440\\u0443\\u0448\\u0435\\u043d\\u0438\\u044f\\u0445 \\u0437\\u0434\\u043e\\u0440\\u043e\\u0432\\u044c\\u044f \\u043f\\u0440\\u043e\\u0446\\u0435\\u0441\\u0441 \\u0441\\u0438\\u043d\\u0442\\u0435\\u0437\\u0430 \\u0438\\u043d\\u0441\\u0443\\u043b\\u0438\\u043d\\u0430 \\u043d\\u0430\\u0440\\u0443\\u0448\\u0430\\u0435\\u0442\\u0441\\u044f, \\u0447\\u0442\\u043e \\u043f\\u0440\\u0438\\u0432\\u043e\\u0434\\u0438\\u0442 \\u043a \\u043d\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0442\\u043a\\u0443 \\u0433\\u043e\\u0440\\u043c\\u043e\\u043d\\u0430     \\u043f\\u0440\\u0438\\u0435\\u043c \\u043d\\u0435\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0445 \\u043f\\u0440\\u0435\\u043f\\u0430\\u0440\\u0430\\u0442\\u043e\\u0432\",\n          \"\\u041f\\u0440\\u043e\\u0434\\u0430\\u043b\\u0438 \\u043f\\u043e\\u043b\\u043e\\u0432\\u0438\\u043d\\u0443 \\u043f\\u0430\\u0447\\u043a\\u0438 \\u041c\\u043e\\u0441\\u043a\\u0432\\u0430. \\u0410\\u043f\\u0442\\u0435\\u043a\\u0430 \\u0413\\u0430\\u043b\\u0443\\u0448\\u043a\\u0438\\u043d\\u0430, \\u0434. 9, \\u043a\\u043e\\u0440\\u043f. 2. \\u041a\\u0443\\u043f\\u0438\\u043b\\u0430 \\u043b\\u0435\\u043a\\u0430\\u0440\\u0441\\u0442\\u0432\\u043e \\u0432 \\u044d\\u0442\\u043e\\u0439 \\u0430\\u043f\\u0442\\u0435\\u043a\\u0435, \\u0430 \\u0432 \\u043f\\u0430\\u0447\\u043a\\u0435 \\u043e\\u043a\\u0430\\u0437\\u0430\\u043b\\u043e\\u0441\\u044c \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u043f\\u043e\\u043b\\u043e\\u0432\\u0438\\u043d\\u0430 \\u0442\\u0430\\u0431\\u043b\\u0435\\u0442\\u043e\\u043a. \\u0423\\u0431\\u0435\\u0434\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u0430\\u044f \\u043f\\u0440\\u043e\\u0441\\u044c\\u0431\\u0430 \\u043a \\u0440\\u0443\\u043a\\u043e\\u0432\\u043e\\u0434\\u0441\\u0442\\u0432\\u0443 - \\u043a\\u043e\\u043d\\u0442\\u0440\\u043e\\u043b\\u0438\\u0440\\u0443\\u0439\\u0442\\u0435 \\u0441\\u043e\\u0442\\u0440\\u0443\\u0434\\u043d\\u0438\\u043a\\u043e\\u0432. \\u042f \\u043f\\u043e\\u043a\\u0443\\u043f\\u0430\\u043b\\u0430 \\u043b\\u0435\\u043a\\u0430\\u0440\\u0441\\u0442\\u0432\\u043e \\u043d\\u0430 \\u043e\\u0442\\u043f\\u0443\\u0441\\u043a, \\u0445\\u043e\\u0440\\u043e\\u0448\\u043e, \\u0447\\u0442\\u043e \\u0432\\u043e\\u0432\\u0440\\u0435\\u043c\\u044f \\u043f\\u043e\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043b\\u0430! \",\n          \"\\u0421\\u043a\\u0430\\u0437\\u043a\\u0438 \\u0442\\u043e \\u043d\\u0435 \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u0439\\u0442\\u0435, \\u0442\\u0430\\u043a\\u043e\\u0435 \\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u0435\\u0441\\u043b\\u0438 \\u0434\\u0435\\u0440\\u0435\\u0432\\u043d\\u044f \\u0432 \\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u0438\\u0445 \\u043a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440\\u0430\\u0445 \\u043e\\u0442 \\u0433\\u043e\\u0440\\u043e\\u0434\\u0430, \\u0441\\u0430\\u043c \\u0436\\u0438\\u0432\\u0443 \\u0432 \\u043f\\u0444\\u043e \\u041e\\u0440\\u0435\\u043d\\u0431\\u0443\\u0440\\u0436\\u044c\\u0435, \\u0443 \\u043d\\u0430\\u0441 \\u0434\\u043e\\u0440\\u043e\\u0433\\u0443 2 \\u0434\\u043d\\u044f \\u043f\\u043e\\u0447\\u0438\\u0441\\u0442\\u0438\\u0442\\u044c \\u043d\\u0435 \\u043c\\u043e\\u0433\\u043b\\u0438, \\u0438\\u0431\\u043e 1 \\u0442\\u0440\\u0430\\u043a\\u0442\\u043e\\u0440 \\u043d\\u0430 3 \\u0434\\u0435\\u0440\\u0435\\u0432\\u043d\\u0438 \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred1 = automl.predict(test.iloc[:5000]).data\n",
    "pred2 = automl.predict(test.iloc[5000:10000]).data\n",
    "pred3 = automl.predict(test.iloc[10000:15000]).data\n",
    "pred4 = automl.predict(test.iloc[15000:20000]).data\n",
    "pred5 = automl.predict(test.iloc[20000:]).data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZiBaoZ0jjBzU",
    "outputId": "e1aff56f-e391-4bb1-d942-b59e60e0da16"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:29:57] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:30:53] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:31:34] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:32:27] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:32:38] Feature concated__text transformed\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "res = []"
   ],
   "metadata": {
    "id": "WbToRxlgmkwC"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in pred1:\n",
    "    res.append(np.argmax(i.data))\n",
    "for i in pred2:\n",
    "    res.append(np.argmax(i.data))\n",
    "for i in pred3:\n",
    "   res.append(np.argmax(i.data))\n",
    "for i in pred4:\n",
    "    res.append(np.argmax(i.data))\n",
    "for i in pred5:\n",
    "    res.append(np.argmax(i.data))"
   ],
   "metadata": {
    "id": "qyma5qUDlk8N"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pd.DataFrame(pd.Series(np.array(res))).to_csv('submission.csv', sep=',', index=True, encoding='utf-8')"
   ],
   "metadata": {
    "id": "VzLgqgr6mtnS"
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(automl,'models/automl_from_chris.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
