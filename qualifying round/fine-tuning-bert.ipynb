{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:50:25.067748Z",
     "start_time": "2024-03-24T20:50:22.623815Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, Dataset\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:57:08.615073Z",
     "start_time": "2024-03-24T20:57:08.609215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/first_task/train.csv')\n",
    "test = pd.read_csv('../data/first_task/test.csv')\n",
    "sample = pd.read_csv('../data/first_task/sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:42:37.209652Z",
     "start_time": "2024-03-24T20:42:34.210638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, test_text, train_label, test_label = train_test_split(train['text'], train['sentiment'], test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:42:38.006103Z",
     "start_time": "2024-03-24T20:42:37.967218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('DeepPavlov/rubert-base-cased-sentence', num_labels=2).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:57:13.525142Z",
     "start_time": "2024-03-24T20:57:10.911258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "seed_all(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:42:42.305189Z",
     "start_time": "2024-03-24T20:42:42.296343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "48146"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len_train = [len(str(i).split()) for i in train['text']]\n",
    "seq_len_test = [len(str(i).split()) for i in test['text']]\n",
    "max_seq_len = max(max(seq_len_test), max(seq_len_train))\n",
    "max_seq_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:42:44.559364Z",
     "start_time": "2024-03-24T20:42:43.094591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "82633     Отель расположен очень удачно(на мой взгляд)-в...\n54230     Великолепное обслуживание. Сотрудники ресепшен...\n121119    Пора уже обнародовать скрываемые властями кост...\n760       Коррупция в неврологическом отделении Я просто...\n132950    отличный отель в современном стиле, есть небол...\n                                ...                        \n119879    Отмечали день рождения небольшой компании , вс...\n103694    Номер был с окнами во двор, поэтому было тихо ...\n131932    мы с подругой учимся рядом - потому и забегаем...\n146867    Возможно, у нас бывает, что на внутренний рыно...\n121958    Спасибо Прошли 2курса лечения на дневном стаци...\nName: text, Length: 151912, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:42:45.670Z",
     "start_time": "2024-03-24T20:42:45.662610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_text_array = np.array(train_text.values)\n",
    "test_text_array = np.array(test_text.values)\n",
    "\n",
    "# Преобразуйте массивы NumPy в списки\n",
    "train_text_list = train_text_array.tolist()\n",
    "test_text_list = test_text_array.tolist()\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-24T20:42:50.917611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels)\n\u001B[0;32m---> 13\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m Data(\u001B[43mtokens_train\u001B[49m, train_label)\n\u001B[1;32m     14\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m Data(tokens_test, test_label)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokens_train' is not defined"
     ]
    }
   ],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Data(tokens_train, train_label)\n",
    "test_dataset = Data(tokens_test, test_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:50:28.180896Z",
     "start_time": "2024-03-24T20:50:28.127074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {'F1': f1}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T20:50:41.054578Z",
     "start_time": "2024-03-24T20:50:41.047890Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './results', #Выходной каталог\n",
    "    num_train_epochs = 3, #Кол-во эпох для обучения\n",
    "    per_device_train_batch_size = 8, #Размер пакета для каждого устройства во время обучения\n",
    "    per_device_eval_batch_size = 8, #Размер пакета для каждого устройства во время валидации\n",
    "    weight_decay =0.01, #Понижение весов\n",
    "    logging_dir = './logs', #Каталог для хранения журналов\n",
    "    load_best_model_at_end = True, #Загружать ли лучшую модель после обучения\n",
    "    learning_rate = 1e-5, #Скорость обучения\n",
    "    evaluation_strategy ='epoch', #Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n",
    "    logging_strategy = 'epoch', #Логирование после каждой эпохи\n",
    "    save_strategy = 'epoch', #Сохранение после каждой эпохи\n",
    "    save_total_limit = 1,\n",
    "    seed=21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  tokenizer = tokenizer,\n",
    "                  args = training_args,\n",
    "                  train_dataset = train_dataset,\n",
    "                  eval_dataset = train_dataset,\n",
    "                  compute_metrics = compute_metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_path = \"fine-tune-bert\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_prediction():\n",
    "    test_pred = trainer.predict(test_dataset)\n",
    "    labels = np.argmax(test_pred.predictions, axis = -1)\n",
    "    return labels\n",
    "pred = get_prediction()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
