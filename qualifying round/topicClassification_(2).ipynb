{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZYpComj7E_G"
   },
   "source": [
    "# Классификация тем текстов"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install lightautoml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8-u-4iiOqn1O",
    "outputId": "89c7c64c-7ed5-46f7-e3a7-f51bd3d9a279"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting lightautoml\n",
      "  Downloading lightautoml-0.3.8.1-py3-none-any.whl (416 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m416.4/416.4 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting autowoe>=1.2 (from lightautoml)\n",
      "  Downloading AutoWoE-1.3.2-py3-none-any.whl (215 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m215.7/215.7 kB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting catboost>=0.26.1 (from lightautoml)\n",
      "  Downloading catboost-1.2.3-cp310-cp310-manylinux2014_x86_64.whl (98.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.5/98.5 MB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting cmaes (from lightautoml)\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: holidays in /usr/local/lib/python3.10/dist-packages (from lightautoml) (0.45)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from lightautoml) (3.1.3)\n",
      "Collecting joblib<1.3.0 (from lightautoml)\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m298.0/298.0 kB\u001B[0m \u001B[31m23.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting json2html (from lightautoml)\n",
      "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting lightgbm<=3.2.1,>=2.3 (from lightautoml)\n",
      "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m51.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from lightautoml) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from lightautoml) (1.25.2)\n",
      "Collecting optuna (from lightautoml)\n",
      "  Downloading optuna-3.6.0-py3-none-any.whl (379 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m379.9/379.9 kB\u001B[0m \u001B[31m28.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pandas<2.0.0 in /usr/local/lib/python3.10/dist-packages (from lightautoml) (1.5.3)\n",
      "Collecting poetry-core<2.0.0,>=1.0.0 (from lightautoml)\n",
      "  Downloading poetry_core-1.9.0-py3-none-any.whl (309 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m309.5/309.5 kB\u001B[0m \u001B[31m21.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from lightautoml) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from lightautoml) (1.2.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from lightautoml) (0.13.1)\n",
      "Collecting statsmodels<=0.14.0 (from lightautoml)\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.1/10.1 MB\u001B[0m \u001B[31m78.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch<=2.0.0,>=1.9.0 (from lightautoml)\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m619.9/619.9 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lightautoml) (4.66.2)\n",
      "Collecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.2->lightautoml)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autowoe>=1.2->lightautoml) (3.7.1)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from autowoe>=1.2->lightautoml) (7.4.4)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from autowoe>=1.2->lightautoml) (2023.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from autowoe>=1.2->lightautoml) (1.11.4)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.10/dist-packages (from autowoe>=1.2->lightautoml) (5.0.2)\n",
      "Collecting sphinx-rtd-theme (from autowoe>=1.2->lightautoml)\n",
      "  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m35.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost>=0.26.1->lightautoml) (0.20.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost>=0.26.1->lightautoml) (5.15.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost>=0.26.1->lightautoml) (1.16.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0->lightautoml) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->lightautoml) (3.4.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<=0.14.0->lightautoml) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels<=0.14.0->lightautoml) (24.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (1.12)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.0/21.0 MB\u001B[0m \u001B[31m31.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m849.3/849.3 kB\u001B[0m \u001B[31m51.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.8/11.8 MB\u001B[0m \u001B[31m57.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m557.1/557.1 MB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m317.1/317.1 MB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.4/168.4 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.6/54.6 MB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m102.6/102.6 MB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m173.2/173.2 MB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m177.1/177.1 MB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.6/98.6 kB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting triton==2.0.0 (from torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.3/63.3 MB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.0,>=1.9.0->lightautoml) (67.7.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml) (3.27.9)\n",
      "Collecting lit (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\n",
      "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m161.0/161.0 kB\u001B[0m \u001B[31m19.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Installing backend dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->lightautoml) (2.1.5)\n",
      "Collecting alembic>=1.5.0 (from optuna->lightautoml)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m233.4/233.4 kB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting colorlog (from optuna->lightautoml)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->lightautoml) (2.0.29)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->lightautoml)\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.7/78.7 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.1.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (3.0.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost>=0.26.1->lightautoml) (8.2.3)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->autowoe>=1.2->lightautoml) (1.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->autowoe>=1.2->lightautoml) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.8)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.6)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.7)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.16.1)\n",
      "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (0.18.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.14.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (0.7.16)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.31.0)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->autowoe>=1.2->lightautoml)\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.1/121.1 kB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (2024.2.2)\n",
      "Building wheels for collected packages: json2html, lit\n",
      "  Building wheel for json2html (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7593 sha256=94d93b9d703d37d6cdcaee4d69e0056cdcfd1dfbf2df8dfcb82717865bff16e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/d8/b3/6f83a04ab0ec00e691de794d108286bb0f8bcdf4ade19afb57\n",
      "  Building wheel for lit (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=332b2008ff97893c83b529b9691416d4727072d905254bb3051b1f16392c5c9a\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
      "Successfully built json2html lit\n",
      "Installing collected packages: StrEnum, lit, json2html, poetry-core, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, Mako, joblib, colorlog, cmaes, nvidia-cusolver-cu11, nvidia-cudnn-cu11, alembic, statsmodels, sphinxcontrib-jquery, optuna, lightgbm, catboost, sphinx-rtd-theme, autowoe, triton, torch, lightautoml\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.3.2\n",
      "    Uninstalling joblib-1.3.2:\n",
      "      Successfully uninstalled joblib-1.3.2\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.14.1\n",
      "    Uninstalling statsmodels-0.14.1:\n",
      "      Successfully uninstalled statsmodels-0.14.1\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 4.1.0\n",
      "    Uninstalling lightgbm-4.1.0:\n",
      "      Successfully uninstalled lightgbm-4.1.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.1+cu121\n",
      "    Uninstalling torch-2.2.1+cu121:\n",
      "      Successfully uninstalled torch-2.2.1+cu121\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
      "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
      "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed Mako-1.3.2 StrEnum-0.4.15 alembic-1.13.1 autowoe-1.3.2 catboost-1.2.3 cmaes-0.10.0 colorlog-6.8.2 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8.1 lightgbm-3.2.1 lit-18.1.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 optuna-3.6.0 poetry-core-1.9.0 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1 statsmodels-0.14.0 torch-2.0.0 triton-2.0.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "joblib"
        ]
       },
       "id": "730f50f89345470a82b30f1814666011"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2PqiLl-fGJ9c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.text_presets import TabularNLPAutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oqeQQQ67VEK"
   },
   "source": [
    "# Препроцессинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "rrDTq-TiG4Oz",
    "outputId": "2aaa01b6-b6d7-436c-bf12-ec419adc6a49"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/train.csv'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-86a8ab7e2a48>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/content/drive/MyDrive/train.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m                     \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnew_arg_name\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_arg_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    329\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfind_stack_level\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m                 )\n\u001B[0;32m--> 331\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    332\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    333\u001B[0m         \u001B[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    948\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 950\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    951\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    952\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    603\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 605\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1440\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1441\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1442\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1443\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1444\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1733\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1734\u001B[0m                     \u001B[0mmode\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\"b\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1735\u001B[0;31m             self.handles = get_handle(\n\u001B[0m\u001B[1;32m   1736\u001B[0m                 \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1737\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    855\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 856\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    857\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    858\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/train.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EY7x_Nauvih",
    "outputId": "b81ef147-a7a9-4bf5-865e-44032517920d"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(14919978, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t6_xJzDSTGor"
   },
   "outputs": [],
   "source": [
    "topics = [\n",
    "    'work', 'news', 'sports', 'music', 'movies', 'politics', 'phones',\n",
    "    'self-driving cars', 'family', 'cars', 'climate change', 'languages',\n",
    "    'business', 'health', 'science', 'style', 'opinion', 'economy',\n",
    "    'history', 'technology', 'affair', 'development', 'mobility'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JTXEDrIxEOn",
    "outputId": "d3e66dd1-8e13-45ea-f384-21fbd237f992"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MJ4IrKBMTpbj"
   },
   "outputs": [],
   "source": [
    "for topic in topics:\n",
    "    df[topic] = df['labels'].str.contains(topic).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtoUZba97cia"
   },
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TM46i9VYT1xF"
   },
   "outputs": [],
   "source": [
    "task = Task('binary')\n",
    "\n",
    "text_params = {\n",
    "    'lang': 'en'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Идея"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Библиотека AutoML еще плохо работает с MultiLabel классификацией, поэтому мы решили обучать не 1 большую мультилейбловую модель, а 23 модели бинарной классификации, каждая из которых будет определять - относится текст к данному топику или нет\n",
    "\n",
    "#### Таким образом мы разбиваем нашу задачу на множество подзадач бинарной классификации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "topic = topics[15]\n",
    "topic"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H7gocDZAjjrX",
    "outputId": "c67c8903-a90e-4121-9d83-aa95805c5cab"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'style'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "new_df = df[['text', topic]]"
   ],
   "metadata": {
    "id": "XAvolAe7jy_V"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "topic_df = new_df.loc[new_df[topic] == 1]\n",
    "len(topic_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MG4y-ySfj4Fq",
    "outputId": "9166f7da-41ca-4b49-daad-c6466c005e03"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3646723"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "non_topic_df = new_df.loc[new_df[topic] == 0]\n",
    "len(non_topic_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLoTRWaEj_vo",
    "outputId": "17a47e06-7969-4fae-d6c4-79c157312e33"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3646723"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Берем небольшой батч на обучение так, чтобы было одинаковое количество текстов, одни - которые не подпадают под топик, а другие - попадают"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "topic_df = topic_df.sample(50000)\n",
    "non_topic_df = non_topic_df.sample(50000)"
   ],
   "metadata": {
    "id": "wSPA05dTkxAh"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "new_df = pd.concat([topic_df, non_topic_df], ignore_index=True)\n",
    "\n",
    "train, test = train_test_split(new_df, random_state=42)"
   ],
   "metadata": {
    "id": "g1tljCPokIPp"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "roles = {\n",
    "    'target': topic,\n",
    "    'text': 'text'\n",
    "}"
   ],
   "metadata": {
    "id": "fBWkd--tkJVY"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "automl = TabularNLPAutoML(\n",
    "    task=task,\n",
    "    text_params=text_params\n",
    ")"
   ],
   "metadata": {
    "id": "FTZzTxvTkQre"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_predictions = automl.fit_predict(train, roles=roles, verbose=0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTheFbsOkUrH",
    "outputId": "8f53ab32-0219-489c-b0c2-4a9b00357a02"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001B[1mTrain data shape: (75000, 2)\u001B[0m\n",
      "\n",
      "INFO:lightautoml.automl.base:Layer \u001B[1m1\u001B[0m train process start. Time left 3599.66 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7182094900540736\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7184432470036781\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.718612904712259\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7199339679577395\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7210409286661943\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7305274691375803\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7360217446539166\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7454919779148659\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7472193614203914\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7484385430006675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.7484385430006675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.7484385430006675\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.72630109971449\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7265328470346278\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7266862455141497\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7277467548639178\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7295134597797776\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7367125963118099\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7419023686021878\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7496264366063448\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7507813780050663\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7513705975105177\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.7513705975105177\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.7513705975105177\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7131805489127966\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7134133266334686\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7135726291160509\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7148865337971791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7164986434328968\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7251721967292668\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.730962980531209\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7409364833014729\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7429267659332355\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7429267787332421\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.7445154579568134\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.7445154579568134\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.7445154579568134\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m finished. score = \u001B[1m0.7480960085385036\u001B[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 3568.19 secs\n",
      "\n",
      "100%|██████████| 75000/75000 [01:07<00:00, 1110.23it/s]\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text fitted\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.03, 'num_leaves': 64, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 1200, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.648022\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.648248\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.647652\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[191]\tvalid's auc: 0.648325\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.651512\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.652279\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.652013\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.651383\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[237]\tvalid's auc: 0.652599\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.648526\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.649197\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.649626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.649286\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[253]\tvalid's auc: 0.649828\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m finished. score = \u001B[1m0.6502006554718676\u001B[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001B[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001B[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 3313.03 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001B[1mLayer 1 training completed.\u001B[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001B[1m0.7532934756139271\u001B[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001B[1m0\u001B[0m: score = \u001B[1m0.7587999974394297\u001B[0m, weights = \u001B[1m[0.6716526  0.32834738]\u001B[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001B[1m1\u001B[0m: score = \u001B[1m0.7587999974394297\u001B[0m, weights = \u001B[1m[0.6716526  0.32834738]\u001B[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001B[1mAutoml preset training completed in 287.98 seconds\u001B[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.67165 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.32835 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_predictions = automl.predict(test, batch_size=1000)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "DPnjF-DqkWcC",
    "outputId": "38ccd87e-f6f6-4651-e1c2-b9a3b8034ded"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'automl' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-8ea2cc2b431a>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_predictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mautoml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'automl' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'TRAIN SCORE: {roc_auc_score(train[topic].values, train_predictions.data[:, 0])}')\n",
    "print(f'TEST SCORE: {roc_auc_score(test[topic].values, test_predictions.data[:, 0])}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7rSu1IwrkZud",
    "outputId": "0c27f691-0ba8-48bc-92c5-29d7e1d1a1ba"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN SCORE: 0.7587999974394297\n",
      "TEST SCORE: 0.7627892129711551\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Неплохо, учитывая, что у нас немного текстов на обучение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKFcd-jy7umo"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "submission = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
    "submission"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "MQIm9bVal8yM",
    "outputId": "680d4218-b407-4905-9dea-80e1b637874d"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      text\n",
       "0        noraemingi CaratExolAtiny ATEEZofficial YES QU...\n",
       "1        Not to mention I take advantage of Steam Cloud...\n",
       "2         MlindoRSA Dropping tomorrow Yekela NewMusic f...\n",
       "3         Singh's supporters refused to hand over the b...\n",
       "4         Founded in 1981, Bafna Pharmaceutical, which ...\n",
       "...                                                    ...\n",
       "3729985   CBSins69 love it n follow me nNaughtySinsatio...\n",
       "3729986   SOFTJEETH this is still my peak jisung nothin...\n",
       "3729987   There's interest from developers in Windows P...\n",
       "3729988  ***Seriously it seems like you have played a l...\n",
       "3729989              liddlexie idk why but this was funny \n",
       "\n",
       "[3729990 rows x 1 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-57ded081-0dc7-4263-865a-76e76821b025\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noraemingi CaratExolAtiny ATEEZofficial YES QU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not to mention I take advantage of Steam Cloud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MlindoRSA Dropping tomorrow Yekela NewMusic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singh's supporters refused to hand over the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Founded in 1981, Bafna Pharmaceutical, which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729985</th>\n",
       "      <td>CBSins69 love it n follow me nNaughtySinsatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729986</th>\n",
       "      <td>SOFTJEETH this is still my peak jisung nothin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729987</th>\n",
       "      <td>There's interest from developers in Windows P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729988</th>\n",
       "      <td>***Seriously it seems like you have played a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729989</th>\n",
       "      <td>liddlexie idk why but this was funny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729990 rows × 1 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ded081-0dc7-4263-865a-76e76821b025')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-57ded081-0dc7-4263-865a-76e76821b025 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-57ded081-0dc7-4263-865a-76e76821b025');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9f5e799b-4622-4f1b-bbf2-eae2e2aa574a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f5e799b-4622-4f1b-bbf2-eae2e2aa574a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9f5e799b-4622-4f1b-bbf2-eae2e2aa574a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "submission"
      }
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "rBC5WmoSB50b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "XXSPtDJWB6On"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "preds = automl.predict(submission, batch_size=100_000)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnHSKwtRmMrs",
    "outputId": "bf8b6cea-6071-46b0-e8c0-bdb8cb75182c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n",
      "INFO3:lightautoml.transformers.text:Feature concated__text transformed\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "И где-то после 30 батча (из 40) модель падала из-за нехватки оперативки, поэтому получить предикты не получилось, однако на обучении при валидации мы набирали 70+ процентов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Думаю, что если бы датасет был поменьше либо если бы у нас были бОльшие вычислительные мощности, то задача бы решилась со скором под 70-80%, но увы :("
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее можете посмотреть ноутбук с MVP модели суммаризации, модель лежит в ноутбуке, а сама полноценная реализация бота - в другой ветке"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "preds"
   ],
   "metadata": {
    "id": "MRVOZuS-mir2"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
